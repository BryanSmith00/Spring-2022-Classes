# Data Science Lecture 14
Week 7 Thursday

## Gradient Descent and Loss Functions
--- 

pick a starting point (w)<br>
repeat until loss doesn't decrease in all dimensions
* Pick a dimension
* move a small amount in that dimension towards decreasing loss (using the derivative)